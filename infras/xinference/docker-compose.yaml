version: '3.8'

services:
  xinference:
    # image: xprobe/xinference:v0.11.3
    image: xprobe/xinference:v0.12.0
    ports:
      - "9308:9997"
    volumes:
      # model weights directory on host machine
      - /home/models:/models
      # Replace <xinference_home> with your xinference home path on the host machine
      - ./xinference_home:/root/.xinference
      # Replace <huggingface_cache_dir> with your huggingface cache path, default is
      # <home_path>/.cache/huggingface
      - /home/dev/.cache/huggingface:/root/.cache/huggingface
      # If models are downloaded from modelscope, replace <huggingface_cache_dir> with
      # your modelscope cache path, default is <home_path>/.cache/modelscope
      - /home/dev/.cache/modelscope:/root/.cache/modelscope
    environment:
      # Default to use ModelScope for model download
      XINFERENCE_MODEL_SRC: modelscope
      # reserved GPU
      CUDA_VISIBLE_DEVICES: 0,1,2,3,4
      # Home dir for xinference, default to /root/.xinference
      #- XINFERENCE_HOME: ./xinference_home
    command: xinference-local --host 0.0.0.0 --port 9997
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['0', '1', '2', '3', '4']
              #count: all